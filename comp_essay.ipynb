{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp API Project!\n",
    "Created by Aaron Codrington and Diego Riverbay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro:\n",
    "\n",
    " \n",
    "Picture this. You're hungry, famished, literally starving. You need food and not just any food you need it fast. So you go to a fast food place and surprise, instead of the delicious food you hoped for it's bad...terrible..honestly a waste of your money. We've all been there and it doesn't feel too good. Terrible fast food experiences like this served as an inspiration for us to utilize the Yelp Fusion API in order to find the highest rated food places in our area. But then I realized why stop there, why stop at just finding good places near me. What happens when I travel or want to go somewhere new? from this thought we came up with the question \"Which cities have the highest average rating for fast food.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology:\n",
    "Once we decided on a feasible question we needed to find a way to visually model said question. In order to generate a visual model we first needed data. In order to get data we used the Yelp Fusion API. This API allows us to gather data about businesses based on a set of parameters. In order to first reach the data we needed to create a function that would request data from the Yelp API, interpret it, then create a csv file containing the specific subset of data we needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from api_setup import API_KEY\n",
    "import numpy as np\n",
    "\n",
    "API_HOST = 'https://api.yelp.com'\n",
    "SEARCH_PATH = '/v3/businesses/search'\n",
    "ENDPOINT = \"https://api.yelp.com/v3/businesses/search\"\n",
    "API_AUTH = {'Authorization': 'bearer %s' % API_KEY}\n",
    "\n",
    "PARAMETERS = {'location':'San Francisco',\n",
    "                'limit':10,#limits to 10 searches\n",
    "                'radius':1000,\n",
    "                'term':'Fast Food'}#optional term like coffee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search parameters we decided to use are \"limit\" which limits the amount of data we call from the API, \"Radius\" which is the area around the location point, \"term\" which is an optional refining parameter that allows us to search businesses that only serve a specific thing like \"fast food\" for example, and lastly \"location\" is just the general location of businesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we specified what data we should be getting we needed to request said data. the code segment below allows us to request data using the Yelp API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url=ENDPOINT, \n",
    "                        params=PARAMETERS, \n",
    "                        headers=API_AUTH)\n",
    "\n",
    "#need this line to convert out of j form\n",
    "yelp_data = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The requested data returns in the form of a json file. the line \"yelp_data = response.json()\" converts the json data we received into a readable form which can be printed out and read. This data is  stored under the name yelp_data. We then define buisness_list and rating_list as blank lists in order to append the readable data in yelp_data to them. Next we search all the data in yelp_data for the category \"businesses\" and then the sub categories name, and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_list = []\n",
    "rating_list = []\n",
    "\n",
    "for rate in yelp_data['businesses']:\n",
    "    business_list.append(rate['name'])\n",
    "    rating_list.append(rate['rating'])\n",
    "\n",
    "print(business_list) #sanity checking\n",
    "print(rating_list) #sanity checking\n",
    "\n",
    "#saving data to csv file\n",
    "#this way saves data to data storage/stored_data\n",
    "np.savetxt('data_storage/single_stored_data.csv', \\\n",
    "    list(zip(business_list, rating_list)), delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last line of the function saves the data as a .csv file labeled single_stored_data.csv inside the data_storage folder. This data can then be read using the basic_graph_data function we created. This first function was the basis for all of our other functions and served as the base code which we can continuously improve upon in order to better suit what data we needed to find. From this original base code, the functions single_use_rating_search, multi_use_rating_search, and expanded_search were built. These functions all worked off the basis of requesting data from the API based upon parameters and storing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we had our stored data we then created graphing functions in order to graph the data we saved to csv files. \n",
    "avg_finder which was the most complex of the graphing functions takes in a csv data file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions:\n",
    " \n",
    "Honestly the most difficult part of this entire project was pivoting. We were very stuck on using the original APIMedic API and it took way too long for us to finally pivot into a more feasible project. On top of that we had to re-assess the scope of our new project and what work we could do with an even more limited time frame. Working with the data and creating new functions under that time constraint was extremely hard however it was also a great learning experience. We both noticed that as we wrote functions the overall time it took to test, and make sure the functions worked was decreased. It is clear from completing this project that our knowledge of how to use python has definitely been expanded.\n",
    " \n",
    "While completing this project we stumbled upon many different ethical and contextual, and societal implications of using the yelp API that were not apparent at first glance. After the pivot our first idea for using the Yelp API was to find popular franchises, analyze the reviews and ratings, then analyze the area's demographic/rate of poverty. While it was an interesting concept to incorporate how the United states intentionally places certain demographics in areas and then builds fast food places around them (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4783380/), we were quickly informed that it was not a great idea. While we were puzzled for a second we reflected and agreed that it was not the best idea. If we did proceed with that project our data would essentially be saying that one franchise is statistically doing better than the others because a certain demographic is surrounding it. This would not only reinforce negative stereotypes about certain groups but it could also lead to people using our data to \"prove\" one group is somehow better or worse than the others. Overall it was very enlightening to learn about the impact of our code and the ethical, contextual, and societal implications it could have.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95708c253e485dfee396183f25509c4e18d98a2c22003c5ececa486f5f235a36"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
